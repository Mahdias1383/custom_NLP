{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fatemeh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fatemeh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Fatemeh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "C:\\Users\\Fatemeh\\AppData\\Local\\Temp\\ipykernel_22276\\2826084742.py:52: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('train_data.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "words_to_keep = {\n",
    "    \"good\", \"bad\", \"perfect\",'great', \"poor\",\"nice\", \"amazing\", \"disappointing\", \"excellent\", \n",
    "    \"terrible\", \"great\", \"awful\", \"best\", \"worst\", \"nice\", \"love\", \"hate\", \"confident\",\"service\",\n",
    "    \"recommend\", \"quality\", \"worth\", \"value\", \"works\", \"needs\", \"lasts\", \"ordinary\", \"successful\",\"unsuccessful\"\n",
    "    \"charges\", \"holds\", \"fits\", \"connects\", \"easy\", \"hard\", \"fast\", \"slow\", \"insult\",\n",
    "    \"durable\", \"price\", \"money\", \"buy\", \"purchase\", \"waste\", \"deal\", \"cost\", \"cancel\",\n",
    "    \"return\", \"refund\", \"replace\", \"remote\", \"tablet\", \"charger\", \"cord\", \"level\",\"fail\",\"finally\",\n",
    "    \"cable\", \"battery\", \"screen\", \"URC\", \"Roku\", \"garantee\", \"warranty\",\"common\",\"experience\"\n",
    "}\n",
    "\n",
    "contractions = {\n",
    "    \"can't\": \"cannot\", \"won't\": \"will not\", \"n't\": \" not\", \"'re\": \" are\",\n",
    "    \"'s\": \" is\", \"'d\": \" would\", \"'ll\": \" will\", \"'t\": \" not\",\n",
    "    \"'ve\": \" have\", \"'m\": \" am\", \"it's\": \"it is\", \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\", \"here's\": \"here is\", \"what's\": \"what is\",\n",
    "    \"who's\": \"who is\", \"how's\": \"how is\", \"i've\": \"i have\", \"you've\": \"you have\",\n",
    "    \"they've\": \"they have\", \"we've\": \"we have\", \"i'd\": \"i would\", \"you'd\": \"you would\",\n",
    "    \"he'd\": \"he would\", \"she'd\": \"she would\", \"they'd\": \"they would\",\n",
    "    \"i'll\": \"i will\", \"you'll\": \"you will\", \"he'll\": \"he will\", \"she'll\": \"she will\",\n",
    "    \"we'll\": \"we will\", \"they'll\": \"they will\", \"isn't\": \"is not\", \"aren't\": \"are not\",\n",
    "    \"wasn't\": \"was not\", \"weren't\": \"were not\", \"haven't\": \"have not\",\n",
    "    \"hasn't\": \"has not\", \"hadn't\": \"had not\", \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\", \"didn't\": \"did not\", \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\", \"can't\": \"cannot\", \"couldn't\": \"could not\",\n",
    "    \"shouldn't\": \"should not\", \"mightn't\": \"might not\", \"mustn't\": \"must not\"\n",
    "}\n",
    "\n",
    "# Important stopwords to retain for sentiment\n",
    "important_stopwords = {\"not\", \"no\", \"never\", \"very\", \"all\", \"any\", \"some\", \"none\", \"only\", \"too\", \"quite\", \"most\", \"more\", \"less\"}\n",
    "\n",
    "# Words indicating negation\n",
    "negation_words = {\"not\", \"no\", \"never\", \"none\", \"nothing\", \"nobody\", \"neither\", \"nowhere\", \"hardly\", \"scarcely\", \"barely\", \"without\", \"doesn’t\", \"isn’t\", \"wasn’t\", \"shouldn’t\", \"wouldn’t\", \"couldn’t\", \"don’t\", \"can’t\", \"didn’t\"}\n",
    "\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('train_data.csv')\n",
    "\n",
    "# Combine 'summary' and 'reviewText' into a single text column\n",
    "data['text'] = data['summary'].fillna('') + \" \" + data['reviewText'].fillna('')\n",
    "\n",
    "# Define preprocessing function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_text(text):\n",
    "    # 1. Lowercase text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Expand contractions\n",
    "    for contraction, expanded in contractions.items():\n",
    "        text = re.sub(r'\\b' + re.escape(contraction) + r'\\b', expanded, text)\n",
    "\n",
    "    # 3. Remove punctuation (keeping sentiment-relevant symbols if needed)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # 4. Handle repeated characters (e.g., \"soooo good\" -> \"so good\")\n",
    "    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)  # Reduces characters occurring 3+ times to 2 (e.g., \"loooove\" -> \"loove\")\n",
    "    \n",
    "    # 5. Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # 6. Remove stopwords while keeping important ones for sentiment or in `words_to_keep`\n",
    "    tokens = [\n",
    "        word for word in tokens \n",
    "        if word not in stop_words or word in important_stopwords or word in words_to_keep\n",
    "    ]\n",
    "\n",
    "    # 7. Lemmatize tokens\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # 8. Emphasize negations (e.g., \"not good\" becomes \"not good_NEG\")\n",
    "    emphasized_tokens = []\n",
    "    negate = False\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in negation_words:\n",
    "            negate = True\n",
    "            emphasized_tokens.append(token)\n",
    "        elif negate:\n",
    "            emphasized_tokens.append(f\"{token}_NEG\")\n",
    "            negate = False\n",
    "        else:\n",
    "            emphasized_tokens.append(token)\n",
    "\n",
    "    # 9. Rejoin tokens into processed text\n",
    "    processed_text = \" \".join(emphasized_tokens)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Apply preprocessing\n",
    "data['text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Split data\n",
    "X = data['text']\n",
    "y = data['overall']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Micro Averaged): 0.7103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define a pipeline with TF-IDF and Logistic Regression\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000, ngram_range=(1, 3))),\n",
    "    ('clf', LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=5000))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average='micro')\n",
    "print(f\"F1 Score (Micro Averaged): {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall\n",
       "5    461485\n",
       "4    156514\n",
       "1     82950\n",
       "3     81239\n",
       "2     56756\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall\n",
       "1    56756\n",
       "3    56756\n",
       "5    56756\n",
       "2    56756\n",
       "4    56756\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def sampling(df, num_target, each_class_size):\n",
    "    min_class_size = min(each_class_size, df[num_target].value_counts().min())\n",
    "    balanced_df = pd.concat([\n",
    "        df[df[num_target] == sentiment].sample(min_class_size, replace=True)\n",
    "        for sentiment in df[num_target].unique()\n",
    "    ])\n",
    "    return balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Balance the entire dataset\n",
    "balanced_data = sampling(data, num_target='overall', each_class_size=200000)  # Set each_class_size as desired\n",
    "\n",
    "balanced_data.overall.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Micro Averaged): 0.6050\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.71      0.69     11300\n",
      "           2       0.53      0.51      0.52     11279\n",
      "           3       0.52      0.50      0.51     11491\n",
      "           4       0.58      0.55      0.56     11374\n",
      "           5       0.70      0.76      0.73     11312\n",
      "\n",
      "    accuracy                           0.61     56756\n",
      "   macro avg       0.60      0.61      0.60     56756\n",
      "weighted avg       0.60      0.61      0.60     56756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split balanced data\n",
    "X1 = balanced_data['text']\n",
    "y1 = balanced_data['overall']\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=0)\n",
    "\n",
    "# Define and train pipeline\n",
    "pipeline1 = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000, ngram_range=(1, 3))),\n",
    "    ('clf', LogisticRegression(class_weight='balanced', multi_class='multinomial', solver='lbfgs', max_iter=10000))\n",
    "])\n",
    "\n",
    "pipeline1.fit(X_train1, y_train1)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred1 = pipeline1.predict(X_test1)\n",
    "f1 = f1_score(y_test1, y_pred1, average='micro')\n",
    "print(f\"F1 Score (Micro Averaged): {f1:.4f}\")\n",
    "print(classification_report(y_test1, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Assuming data has already been preprocessed and split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(data['text'], data['overall'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define pipeline with SMOTE and Logistic Regression with class weights\n",
    "pipeline2 = ImbPipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=20000, ngram_range=(1, 2))),\n",
    "    ('smote', SMOTE(random_state=42)),  # Oversample minority classes\n",
    "    ('clf', LogisticRegression(class_weight='balanced', multi_class='multinomial', solver='lbfgs', max_iter=5000))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipeline2.fit(X_train2, y_train2)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred2 = pipeline2.predict(X_test2)\n",
    "f1 = f1_score(y_test2, y_pred2, average='micro')\n",
    "print(f\"F1 Score (Micro Averaged): {f1:.4f}\")\n",
    "print(classification_report(y_test2, y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import textblob\n",
    "\n",
    "# Custom Transformer to add text length features\n",
    "class TextLengthExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return np.array([[len(text.split()), len(text)] for text in data])\n",
    "\n",
    "# Custom Transformer to add sentiment score\n",
    "class SentimentExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return np.array([textblob.TextBlob(text).sentiment.polarity for text in data]).reshape(-1, 1)\n",
    "\n",
    "# Build pipeline with TF-IDF, additional features, and Gradient Boosting\n",
    "pipeline3 = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('tfidf', TfidfVectorizer(max_features=20000, ngram_range=(1, 2), stop_words='english')),\n",
    "        ('text_length', TextLengthExtractor()),\n",
    "        ('sentiment', SentimentExtractor())\n",
    "    ])),\n",
    "    ('clf', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'features__tfidf__max_features': [10000, 20000, 30000],\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__learning_rate': [0.1, 0.05],\n",
    "    'clf__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "# Grid search for best hyperparameters\n",
    "grid_search = GridSearchCV(pipeline3, param_grid, scoring='f1_micro', cv=3, verbose=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred3 = grid_search.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred3, average='micro')\n",
    "print(f\"Best F1 Score (Micro Averaged): {f1:.4f}\")\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define a pipeline with CountVectorizer and Logistic Regression\n",
    "pipeline4 = Pipeline([\n",
    "    ('count_vec', CountVectorizer(max_features=20000, ngram_range=(1, 3))),\n",
    "    ('clf', LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=5000))\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "pipeline4.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred4 = pipeline4.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred4, average='micro')\n",
    "print(f\"F1 Score (Micro Averaged): {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_data.csv')\n",
    "test_data['text'] = test_data['reviewText'].fillna('').apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "test_predictions = pipeline1.predict(test_data['text'])\n",
    "\n",
    "# Create a DataFrame for submission\n",
    "submission = pd.DataFrame({\n",
    "    'reviewerID': test_data['reviewerID'],  # Adjust this column based on test data format\n",
    "    'predicted_score': test_predictions\n",
    "})\n",
    "\n",
    "# Save submission to a CSV file without an index, as per your requirement\n",
    "submission.to_csv('q2_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the array: 20000\n",
      "Number of unique elements: 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "size = test_predictions.size\n",
    "\n",
    "# Number of unique elements\n",
    "num_unique = len(np.unique(test_predictions))\n",
    "\n",
    "print(\"Size of the array:\", size)\n",
    "print(\"Number of unique elements:\", num_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       predicted\n",
       "0              3\n",
       "1              1\n",
       "2              2\n",
       "3              1\n",
       "4              1\n",
       "...          ...\n",
       "19995          5\n",
       "19996          5\n",
       "19997          5\n",
       "19998          2\n",
       "19999          2\n",
       "\n",
       "[20000 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create a DataFrame from the predictions\n",
    "predictions_df = pd.DataFrame(test_predictions, columns=['predicted'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "predictions_df.to_csv('q2_submission.csv', index=False)\n",
    "predictions_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

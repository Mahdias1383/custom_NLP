{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "mc5PfFpUKMqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# خواندن دیتا ها\n",
        "!unzip \"/content/drive/MyDrive/Project/Dataset/train.zip\" -d \"/content/train\"\n",
        "!unzip \"/content/drive/MyDrive/Project/Dataset/validation.zip\" -d \"/content/validation\""
      ],
      "metadata": {
        "id": "QYU06Z3f4JPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import average_precision_score"
      ],
      "metadata": {
        "id": "wSysoIIG7HHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# مسیر استخراج فایل‌ها\n",
        "train_dir = \"/content/train/train\"\n",
        "validation_dir = \"/content/validation/validation\""
      ],
      "metadata": {
        "id": "qyVRi1duI4rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# نمایش محتویات پوشه‌های train و validation\n",
        "print(\"Train files:\", os.listdir(train_dir)[:10])  # نمایش 10 فایل اول\n",
        "print(\"Validation files:\", os.listdir(validation_dir)[:10])"
      ],
      "metadata": {
        "id": "QQxmiAUkJDyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_night_images(directory):\n",
        "    files = os.listdir(directory)\n",
        "    for file in files:\n",
        "        if file.startswith('night'):\n",
        "            file_path = os.path.join(directory, file)\n",
        "            os.remove(file_path)  # حذف فایل\n",
        "\n",
        "# حذف تصاویر شب از پوشه‌های train و validation\n",
        "remove_night_images(train_dir)\n",
        "remove_night_images(validation_dir)\n",
        "\n",
        "# بررسی مجدد پوشه‌ها پس از حذف تصاویر شب\n",
        "print(\"Remaining train files:\", os.listdir(train_dir)[:10])\n",
        "print(\"Remaining validation files:\", os.listdir(validation_dir)[:10])\n"
      ],
      "metadata": {
        "id": "H263E4eIN2oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_images_to_class_dir(source_dir, target_dir, class_name='car_plate'):\n",
        "    class_dir = os.path.join(target_dir, class_name)\n",
        "\n",
        "    if not os.path.exists(class_dir):\n",
        "        os.makedirs(class_dir)\n",
        "\n",
        "    for filename in os.listdir(source_dir):\n",
        "        if filename.endswith('.png') or filename.endswith('.jpg'):\n",
        "            shutil.move(os.path.join(source_dir, filename), os.path.join(class_dir, filename))\n",
        "\n",
        "# انتقال تصاویر به پوشه دسته‌بندی فرضی\n",
        "move_images_to_class_dir(train_dir, train_dir)\n",
        "move_images_to_class_dir(validation_dir, validation_dir)\n"
      ],
      "metadata": {
        "id": "Sj4R7ngCrv3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_xml(xml_file):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    objects = []\n",
        "    for obj in root.findall('object'):\n",
        "        name = obj.find('name').text\n",
        "        bndbox = obj.find('bndbox')\n",
        "        xmin = int(bndbox.find('xmin').text)\n",
        "        ymin = int(bndbox.find('ymin').text)\n",
        "        xmax = int(bndbox.find('xmax').text)\n",
        "        ymax = int(bndbox.find('ymax').text)\n",
        "        objects.append({\n",
        "            'name': name,\n",
        "            'bbox': [xmin, ymin, xmax, ymax],\n",
        "            'class_label': 1  # Assuming 'car_plate' is class 1\n",
        "        })\n",
        "\n",
        "    return root.find('filename').text, objects"
      ],
      "metadata": {
        "id": "KjFDyZLaQpG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(image_dir, xml_dir):\n",
        "    data = []\n",
        "\n",
        "    for xml_file in os.listdir(xml_dir):\n",
        "        if xml_file.endswith('.xml'):\n",
        "            xml_path = os.path.join(xml_dir, xml_file)\n",
        "\n",
        "            # Extract filename from xml_file (without extension)\n",
        "            filename_without_ext = os.path.splitext(xml_file)[0]\n",
        "\n",
        "            # Construct image filename with .jpg extension\n",
        "            image_filename = filename_without_ext + '.jpg'\n",
        "\n",
        "            # Construct the image path\n",
        "            image_path = os.path.join(image_dir, image_filename)\n",
        "\n",
        "            # Parse XML file\n",
        "            _, objects = parse_xml(xml_path)\n",
        "\n",
        "            # Append data (include bounding boxes and class labels)\n",
        "            data.append({\n",
        "                'image_path': image_path,\n",
        "                'bboxes': [obj['bbox'] for obj in objects],\n",
        "                'class_labels': [obj['class_label'] for obj in objects]\n",
        "            })\n",
        "\n",
        "    image_paths = [d['image_path'] for d in data]\n",
        "    bboxes = [d['bboxes'] for d in data]\n",
        "    class_labels = [d['class_labels'] for d in data]\n",
        "\n",
        "    return image_paths, bboxes, class_labels"
      ],
      "metadata": {
        "id": "ZdqYsXQdstr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_bboxes, train_class_labels = load_data('/content/train/train/car_plate', '/content/train/train')\n",
        "validation_images, validation_bboxes, validation_class_labels = load_data('/content/validation/validation/car_plate', '/content/validation/validation')"
      ],
      "metadata": {
        "id": "N8aBUmULsyY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Load an Image for Data Augmentation Test\n",
        "img_path = os.path.join(train_dir, train_images[0])\n",
        "img = load_img(img_path, target_size=(512, 512))  # Use load_img directly\n",
        "\n",
        "# Convert Image to Array\n",
        "x = img_to_array(img)  # Use img_to_array directly\n",
        "x = x.reshape((1,) + x.shape)\n",
        "\n",
        "# Generate and Display Augmented Images\n",
        "i = 0\n",
        "for batch in datagen.flow(x, batch_size=1):\n",
        "    plt.figure(i)\n",
        "    imgplot = plt.imshow(array_to_img(batch[0])) # Use array_to_img directly\n",
        "    plt.show()\n",
        "\n",
        "    i += 1\n",
        "    if i > 5:\n",
        "        break"
      ],
      "metadata": {
        "id": "EwzQPgX7UaMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_images(directory, target_size=(512, 512)):\n",
        "    files = os.listdir(directory)\n",
        "    for file in files:\n",
        "        if file.endswith('.jpg'):  # Assuming all images are in JPG format\n",
        "            img_path = os.path.join(directory, file)\n",
        "            img = Image.open(img_path)\n",
        "            img = img.resize(target_size)\n",
        "            img.save(img_path)\n",
        "\n",
        "# تغییر اندازه تصاویر train و validation به اندازه  512 x 512\n",
        "resize_images('/content/train/train/car_plate', target_size=(512, 512))\n",
        "resize_images('/content/validation/validation/car_plate', target_size=(512, 512))\n",
        "\n",
        "print(\"Images resized to 512x512.\")\n"
      ],
      "metadata": {
        "id": "llP-scNoUczu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(keras.Input(shape=(512, 512, 3)))\n",
        "\n",
        "    # Block 1\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Block 2\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Block 3\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Block 4 (optional, you can add more blocks for deeper features)\n",
        "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Classification Head\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu', kernel_regularizer='l2'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create an instance of the model\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "2G3noc53udOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تعریف EarlyStopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "cEg96NzZ0IJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تعریف ReduceLROnPlateau برای کاهش نرخ یادگیری\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,\n",
        "    patience=3,\n",
        "    min_lr=1e-6\n",
        ")"
      ],
      "metadata": {
        "id": "cy6ZfEqf0ARI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تنظیم seed برای تکرارپذیری نتایج\n",
        "seed = 42\n",
        "\n",
        "# تعریف داده‌افزایی\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "tf.random.set_seed(seed)"
      ],
      "metadata": {
        "id": "EgWz3WuXuj_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(512, 512),\n",
        "    batch_size=64,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(512, 512),\n",
        "    batch_size=64,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "LyX8p1NfzZbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_augmented_images(generator, num_images=9, save=False):\n",
        "    # گرفتن یک دسته از تصاویر و برچسب‌ها از ژنراتور\n",
        "    x_batch, y_batch = next(generator)\n",
        "\n",
        "    # بررسی ابعاد تصویر و تبدیل در صورت نیاز\n",
        "    if np.max(x_batch) > 1:  # اگر داده‌ها در محدوده‌ی [0, 255] باشند، آن‌ها را به [0, 1] تبدیل می‌کنیم\n",
        "        x_batch = x_batch / 255.0\n",
        "\n",
        "    # نمایش تصاویر\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "    for i in range(num_images):\n",
        "        ax = axes.flat[i]\n",
        "        ax.imshow(np.clip(x_batch[i], 0, 1))  # اطمینان از اینکه داده‌ها در محدوده [0, 1] هستند\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # ذخیره کردن تصویر در صورت نیاز\n",
        "    if save:\n",
        "        plt.savefig('augmented_images.png')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# نمایش تصاویر تقویت شده با ذخیره کردن\n",
        "plot_augmented_images(train_generator, save=True)"
      ],
      "metadata": {
        "id": "er1LBlhZz2pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=50,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=len(train_images) // 32,\n",
        "    validation_steps=len(validation_images) // 32\n",
        ")"
      ],
      "metadata": {
        "id": "rT8hb5uTzr3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# رسم نمودار از دست دادن (Loss)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kEzW7BpIz6Z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image_with_bbox(image, bbox, title=\"Prediction\"):\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(image)\n",
        "    # Check if bbox has 4 elements for (xmin, ymin, xmax, ymax)\n",
        "    if len(bbox) == 4:\n",
        "        xmin, ymin, xmax, ymax = bbox\n",
        "    # If bbox is a list containing a single list/tuple with 2 elements\n",
        "    elif len(bbox) == 1 and len(bbox[0]) == 4:\n",
        "        xmin, ymin, xmax, ymax = bbox[0]  # Access the inner list/tuple\n",
        "    # If bbox has 2 elements, assuming (x_center, y_center, width, height)\n",
        "    # This part might need to be adjusted based on your actual bbox format\n",
        "    #elif len(bbox) == 2: # Commenting to see if it addresses the error\n",
        "    #    # Assumed structure (x_center, y_center, width, height)\n",
        "    #    x_center, y_center, width, height = bbox[0] # Access the inner list/tuple\n",
        "    #    xmin = x_center - (width / 2)\n",
        "    #    ymin = y_center - (height / 2)\n",
        "    #    xmax = x_center + (width / 2)\n",
        "    #    ymax = y_center + (height / 2)\n",
        "    else:\n",
        "        raise ValueError(f\"bbox has unexpected format: {bbox}, should have either 4 elements or be a list with a single 4-element list/tuple.\")\n",
        "\n",
        "    rect = plt.Rectangle((xmin * 224, ymin * 224), (xmax - xmin) * 224, (ymax - ymin) * 224,\n",
        "                         linewidth=2, edgecolor='r', facecolor='none')\n",
        "    ax.add_patch(rect)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1MZapvZZ-mfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    img_path = validation_images[i]\n",
        "    true_bbox = validation_class_labels[i][0]\n",
        "\n",
        "    # Load the image with the size expected by the model\n",
        "    img = image.load_img(img_path, target_size=(512, 512, 3))\n",
        "    # Convert image to array\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img / 255.  # Normalize the image\n",
        "\n",
        "    predicted_bbox = model.predict(img)[0]\n",
        "\n",
        "    print(f\"True BBox: {true_bbox}\")\n",
        "    print(f\"Predicted BBox: {predicted_bbox}\")\n",
        "\n",
        "    # Display the original image (not preprocessed) in plot_image_with_bbox\n",
        "    original_img = image.load_img(img_path, target_size=(512, 512))\n",
        "    original_img = image.img_to_array(original_img) / 255.\n",
        "\n",
        "    plot_image_with_bbox(original_img, true_bbox,model, title=\"True BBox\")\n",
        "    plot_image_with_bbox(original_img, predicted_bbox, model title=\"Predicted BBox\")"
      ],
      "metadata": {
        "id": "POML45ba71R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss = model.evaluate(validation_images, validation_labels)\n",
        "print(f\"Validation Loss: {val_loss}\")"
      ],
      "metadata": {
        "id": "eqCAEN91zt0S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}